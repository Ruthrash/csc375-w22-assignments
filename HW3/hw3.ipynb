{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csc375-w22-assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Download the github repo"
      ],
      "metadata": {
        "id": "gCeTQOXXpp2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pairlab/csc375-w22-assignments.git"
      ],
      "metadata": {
        "id": "O0GvEU-appHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Tz-dRoKE2X"
      },
      "source": [
        "#P1 Semantic Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYOwmpUsKOVD"
      },
      "source": [
        "!pip install pypng colormap easydev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdYTB5PKLGJa"
      },
      "source": [
        "%cd /content/csc375-w22-assignments/HW3/p1\n",
        "!mkdir output_train output_test models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHNmIPb5KdN-"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import png\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class FacadeDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, \n",
        "        flag, \n",
        "        dataDir='data', \n",
        "        data_range=(0, 8), \n",
        "        n_class=5, \n",
        "        onehot=False\n",
        "    ):\n",
        "        self.onehot = onehot\n",
        "        print(\"load \"+ flag+\" dataset start\")\n",
        "        print(\"    from: %s\" % dataDir)\n",
        "        print(\"    range: [%d, %d)\" % (data_range[0], data_range[1]))\n",
        "        self.dataset = []\n",
        "        for i in range(data_range[0], data_range[1]):\n",
        "            img = Image.open(os.path.join(dataDir,flag,'eecs442_%04d.jpg' % i))\n",
        "            pngreader = png.Reader(filename=os.path.join(dataDir,flag,'eecs442_%04d.png' % i))\n",
        "            w,h,row,info = pngreader.read()\n",
        "            label = np.array(list(row)).astype('uint8')\n",
        "            img = np.asarray(img).astype(\"f\").transpose(2, 0, 1)/128.0-1.0\n",
        "            label_ = np.asarray(label)\n",
        "            label = np.zeros((n_class, img.shape[1], img.shape[2])).astype(\"i\")\n",
        "            for j in range(n_class):\n",
        "                label[j, :] = label_ == j\n",
        "            self.dataset.append((img, label))\n",
        "        print(\"load dataset done\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, label = self.dataset[index]\n",
        "        label = torch.FloatTensor(label)\n",
        "        if not self.onehot:\n",
        "            label = torch.argmax(label, dim=0)\n",
        "        else:\n",
        "            label = label.long()\n",
        "\n",
        "        return torch.FloatTensor(img), torch.LongTensor(label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B48sQ7DiKEfW"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "N_CLASS=5\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_class = N_CLASS\n",
        "        self.layers = nn.Sequential(\n",
        "            #########################################\n",
        "            ###        TODO: Add more layers      ###\n",
        "            #########################################\n",
        "            nn.Conv2d(3, self.n_class, 1, padding=0),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def save_label(label, path):\n",
        "    '''\n",
        "    Function for ploting labels.\n",
        "    '''\n",
        "    colormap = [\n",
        "        '#000000',\n",
        "        '#0080FF',\n",
        "        '#80FF80',\n",
        "        '#FF8000',\n",
        "        '#FF0000',\n",
        "    ]\n",
        "    assert(np.max(label)<len(colormap))\n",
        "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
        "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
        "    with open(path, 'wb') as f:\n",
        "        w.write(f, label)\n",
        "\n",
        "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
        "    '''\n",
        "    Function for training.\n",
        "    '''\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    net = net.train()\n",
        "    for images, labels in tqdm(trainloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()\n",
        "    end = time.time()\n",
        "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
        "          (epoch, running_loss, end-start))\n",
        "\n",
        "def test(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Function for testing.\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)\n",
        "            loss = criterion(output, labels)\n",
        "            losses += loss.item()\n",
        "            cnt += 1\n",
        "    print(losses / cnt)\n",
        "    return (losses/cnt)\n",
        "\n",
        "\n",
        "def cal_AP(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Calculate Average Precision\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        preds = [[] for _ in range(5)]\n",
        "        heatmaps = [[] for _ in range(5)]\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images).cpu().numpy()\n",
        "            for c in range(5):\n",
        "                preds[c].append(output[:, c].reshape(-1))\n",
        "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
        "\n",
        "        aps = []\n",
        "        for c in range(5):\n",
        "            preds[c] = np.concatenate(preds[c])\n",
        "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
        "            if heatmaps[c].max() == 0:\n",
        "                ap = float('nan')\n",
        "            else:\n",
        "                ap = ap_score(heatmaps[c], preds[c])\n",
        "                aps.append(ap)\n",
        "            print(\"AP = {}\".format(ap))\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_result(testloader, net, device, folder='output_train'):\n",
        "    result = []\n",
        "    cnt = 1\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        cnt = 0\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)[0].cpu().numpy()\n",
        "            c, h, w = output.shape\n",
        "            assert(c == N_CLASS)\n",
        "            y = np.zeros((h,w)).astype('uint8')\n",
        "            for i in range(N_CLASS):\n",
        "                mask = output[i]>0.5\n",
        "                y[mask] = i\n",
        "            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
        "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
        "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
        "            plt.imsave(\n",
        "                './{}/x{}.png'.format(folder, cnt),\n",
        "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
        "\n",
        "            cnt += 1\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # TODO: Adjust batch_size for loaders\n",
        "    train_data   = FacadeDataset(flag='train', data_range=(0,800), onehot=False)\n",
        "    train_loader = DataLoader(train_data, batch_size=1)\n",
        "    val_data     = FacadeDataset(flag='train', data_range=(801,906), onehot=False)\n",
        "    val_loader   = DataLoader(val_data, batch_size=1)\n",
        "\n",
        "    test_data    = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)\n",
        "    test_loader  = DataLoader(test_data, batch_size=1)\n",
        "    ap_data      = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)\n",
        "    ap_loader    = DataLoader(ap_data, batch_size=1)\n",
        "\n",
        "    name = 'starter_net'\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), 1e-3, weight_decay=1e-5)\n",
        "\n",
        "    print('\\nStart training')\n",
        "    for epoch in range(2): # TODO: Change the number of epochs\n",
        "        print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
        "        train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
        "        test(val_loader, net, criterion, device)\n",
        "\n",
        "    print('\\nFinished Training, Testing on test set')\n",
        "    test(test_loader, net, criterion, device)\n",
        "    print('\\nGenerating Unlabeled Result')\n",
        "    result = get_result(test_loader, net, device, folder='output_test')\n",
        "\n",
        "    torch.save(net.state_dict(), 'models/model_{}.pth'.format(name))\n",
        "\n",
        "    cal_AP(ap_loader, net, criterion, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#P2 Object Detection"
      ],
      "metadata": {
        "id": "YKQAE1ZPx_Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/csc375-w22-assignments/HW3/p2"
      ],
      "metadata": {
        "id": "Z0T4LCZtymYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def notebook_init():\n",
        "    # For  notebooks\n",
        "    print('Checking setup...')\n",
        "    from IPython import display  # to display images and clear console output\n",
        "\n",
        "    from utils.general import emojis\n",
        "    from utils.torch_utils import select_device  # imports\n",
        "\n",
        "    display.clear_output()\n",
        "    select_device(newline=False)\n",
        "    print(emojis('Setup complete ✅'))\n",
        "    return display\n",
        "\n",
        "display = notebook_init() "
      ],
      "metadata": {
        "id": "0ICj-b1yyV8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "b83ymlpEyawK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "1. Open `csc375-w22-assignments/HW3/p2/train.py` and implement model parameter freezing at line 128 - line 130.\n",
        "\n",
        "2. After finishing step 1, train the YOLOv3 model on COCO128 for 5 epochs, freezing 10 layers, by running the below cell."
      ],
      "metadata": {
        "id": "e-o9jsnRyzE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 5 --data coco128.yaml --weights yolov3.pt --cache --freeze 10"
      ],
      "metadata": {
        "id": "0eWYeVYPyo-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "\n",
        "Set up the visualization by running the below cell. Note that if you ran the training loop multiple times, you would have additional folder exp2, exp3, etc."
      ],
      "metadata": {
        "id": "Sqt5xgMay3VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source data/images"
      ],
      "metadata": {
        "id": "Zx7M5cQxyxBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Results"
      ],
      "metadata": {
        "id": "Ax-_ueWFzFvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display.Image(filename='runs/detect/exp/Cats_and_dog.jpg', width=600)"
      ],
      "metadata": {
        "id": "79qDqkAky_zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display.Image(filename='runs/detect/exp/bus.jpg', width=600)"
      ],
      "metadata": {
        "id": "PXo7C6yszCAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#P3 Object Pose Estimation"
      ],
      "metadata": {
        "id": "NDW_bLC2Bu6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/csc375-w22-assignments/HW3/p3"
      ],
      "metadata": {
        "id": "zRBS_djXshW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import png\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from PIL import Image\n",
        "import pickle\n",
        "\n",
        "class PyBulletDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, \n",
        "        flag, \n",
        "        dataDir='data'\n",
        "    ):\n",
        "        gt_pose = pickle.load(open(os.path.join(dataDir, flag,'gt_poses.pkl'), 'rb'))\n",
        "        self.dataset = []\n",
        "        if flag == 'train':\n",
        "            num_images = 1000\n",
        "        else:\n",
        "            num_images = 100\n",
        "        for i in range(num_images):\n",
        "            img = Image.open(os.path.join(dataDir, flag,'{:05d}.png'.format(i)))\n",
        "            img = np.asarray(img).astype(\"f\").transpose(2, 0, 1)/128.0-1.0\n",
        "            pos, quat = gt_pose['{:05d}'.format(i)]\n",
        "            self.dataset.append((img, pos, quat))\n",
        "        print(\"load dataset done\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, pos, quat = self.dataset[index]\n",
        "        return torch.FloatTensor(img), torch.FloatTensor(pos), torch.FloatTensor(quat)"
      ],
      "metadata": {
        "id": "zQ6oNp7YCTn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 5, stride=2),\n",
        "            nn.Conv2d(32, 64, 5, stride=2),\n",
        "            nn.Conv2d(64, 128, 5, stride=2),\n",
        "            nn.Conv2d(128, 256, 5, stride=2),\n",
        "            nn.Conv2d(256, 512, 5, stride=2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pos_head = nn.Sequential(\n",
        "            #########################################\n",
        "            ###        TODO: Add more layers      ###\n",
        "            #########################################\n",
        "            nn.Linear(512, 3)\n",
        "        )\n",
        "\n",
        "        self.quat_head = nn.Sequential(\n",
        "            #########################################\n",
        "            ###        TODO: Add more layers      ###\n",
        "            #########################################\n",
        "            nn.Linear(512, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        f = self.layers(images)\n",
        "        f = F.avg_pool2d(f, (12, 17))\n",
        "        f = f.view(-1, f.size(1))\n",
        "        pos = self.pos_head(f)\n",
        "        quat = self.quat_head(f)\n",
        "        return pos, quat\n",
        "\n",
        "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
        "    '''\n",
        "    Function for training.\n",
        "    '''\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    net = net.train()\n",
        "    for images, gt_pos, gt_quat in tqdm(trainloader):\n",
        "        images = images.to(device)\n",
        "        gt_pos = gt_pos.to(device)\n",
        "        gt_quat = gt_quat.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred_pos, pred_quat = net(images)\n",
        "        pos_loss = criterion(pred_pos, gt_pos)\n",
        "        quat_loss = criterion(pred_quat, gt_quat)\n",
        "        loss = pos_loss + quat_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()\n",
        "    end = time.time()\n",
        "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
        "          (epoch, running_loss, end-start))\n",
        "\n",
        "def test(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Function for testing.\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        for images, gt_pos, gt_quat in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            gt_pos = gt_pos.to(device)\n",
        "            gt_quat = gt_quat.to(device)\n",
        "            pred_pos, pred_quat = net(images)\n",
        "            pos_loss = criterion(pred_pos, gt_pos)\n",
        "            quat_loss = criterion(pred_quat, gt_quat)\n",
        "            loss = pos_loss + quat_loss\n",
        "            losses += loss.item()\n",
        "            cnt += 1\n",
        "    print('Test loss:', losses / cnt)\n",
        "    return (losses/cnt)\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # TODO: Adjust batch_size for loaders\n",
        "    train_data   = PyBulletDataset(flag='train')\n",
        "    train_loader = DataLoader(train_data, batch_size=1)\n",
        "    val_data     = PyBulletDataset(flag='val')\n",
        "    val_loader   = DataLoader(val_data, batch_size=1)\n",
        "    test_data    = PyBulletDataset(flag='test')\n",
        "    test_loader  = DataLoader(test_data, batch_size=1)\n",
        "\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), 1e-3, weight_decay=1e-5)\n",
        "\n",
        "    print('\\nStart training')\n",
        "    for epoch in range(2): # TODO: Change the number of epochs\n",
        "        print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
        "        train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
        "        test(val_loader, net, criterion, device)\n",
        "        \n",
        "    print('\\nFinished Training, Testing on test set')\n",
        "    test(test_loader, net, criterion, device)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "LCv8kxhTCZm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}